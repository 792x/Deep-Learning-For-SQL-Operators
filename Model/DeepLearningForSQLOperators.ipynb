{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepLearningForSQLOperators.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPKxCjuldEcJBWBxhI5FQQK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_MY7N12ZYAyk","executionInfo":{"status":"ok","timestamp":1624447900430,"user_tz":-120,"elapsed":4383,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["import numpy as np\n","import random\n","import sys\n","import csv\n","import os\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch import optim\n","import torch.nn.functional as F\n","\n","import time\n","import math\n","import bottleneck as bn\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJa1f_wkYFfq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624447965140,"user_tz":-120,"elapsed":64713,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}},"outputId":"e32f9fce-a3fe-4616-a301-a24440d625c1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tAtwgwYxph7V","executionInfo":{"status":"ok","timestamp":1624447965656,"user_tz":-120,"elapsed":518,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}},"outputId":"bd1f9461-369c-4252-ecb6-5f5c97c6bc6e"},"source":["cd '/content/drive/My Drive/Colab Notebooks/Query Operators'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Query Operators\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UEu2kyOEYHpK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624447965657,"user_tz":-120,"elapsed":6,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}},"outputId":"8c2d5eb6-c59c-4051-ec27-c10af620051b"},"source":["num_iter = 20\n","hidden_size = 32\n","num_layers = 1\n","\n","\n","\n","# only one can be set 1\n","use_embedding = 1\n","use_linear_reduction = 0\n","###\n","atten_decoder = 1\n","use_dropout = 0\n","use_average_embedding = 1\n","\n","weight = 10\n","labmda = 0\n","topk_labels = 3\n","\n","# It should be the same as the reductioned input in decoder's cat function\n","\n","teacher_forcing_ratio = 0\n","MAX_LENGTH = 1000\n","learning_rate = 0.001\n","optimizer_option = 2\n","print_val = 3000\n","use_cuda = torch.cuda.is_available()\n","# use_cuda = False\n","\n","print(torch.cuda.get_device_name(0))\n","print(torch.cuda.device_count())\n","print(f\"Using cuda: {use_cuda}\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Tesla K80\n","1\n","Using cuda: True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Xx1wKR_Y84y","executionInfo":{"status":"ok","timestamp":1624447965952,"user_tz":-120,"elapsed":298,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n","\n","def top_n_indexes(arr, n):\n","    idx = bn.argpartition(arr, arr.size - n, axis=None)[-n:]\n","    width = arr.shape[1]\n","    return [divmod(i, width) for i in idx]\n","\n","\n","def get_precision_recall_Fscore(groundtruth, pred):\n","    a = groundtruth\n","    b = pred\n","    correct = 0\n","    truth = 0\n","    positive = 0\n","\n","    for idx in range(len(a)):\n","        if a[idx] == 1:\n","            truth += 1\n","            if b[idx] == 1:\n","                correct += 1\n","        if b[idx] == 1:\n","            positive += 1\n","\n","    flag = 0\n","    if 0 == positive:\n","        precision = 0\n","        flag = 1\n","        # print('postivie is 0')\n","    else:\n","        precision = correct / positive\n","    if 0 == truth:\n","        recall = 0\n","        flag = 1\n","        # print('recall is 0')\n","    else:\n","        recall = correct / truth\n","\n","    if flag == 0 and precision + recall > 0:\n","        F = 2 * precision * recall / (precision + recall)\n","    else:\n","        F = 0\n","    return precision, recall, F, correct\n","\n","\n","def get_F_score(prediction, test_Y):\n","    jaccard_similarity = []\n","    prec = []\n","    rec = []\n","\n","    count = 0\n","    for idx in range(len(test_Y)):\n","        pred = prediction[idx]\n","        T = 0\n","        P = 0\n","        correct = 0\n","        for id in range(len(pred)):\n","            if test_Y[idx][id] == 1:\n","                T = T + 1\n","                if pred[id] == 1:\n","                    correct = correct + 1\n","            if pred[id] == 1:\n","                P = P + 1\n","\n","        if P == 0 or T == 0:\n","            continue\n","        precision = correct / P\n","        recall = correct / T\n","        prec.append(precision)\n","        rec.append(recall)\n","        if correct == 0:\n","            jaccard_similarity.append(0)\n","        else:\n","            jaccard_similarity.append(2 * precision * recall / (precision + recall))\n","        count = count + 1\n","\n","    print(\n","        'average precision: ' + str(np.mean(prec)))\n","    print('average recall : ' + str(\n","        np.mean(rec)))\n","    print('average F score: ' + str(\n","        np.mean(jaccard_similarity)))\n","\n","\n","def get_DCG(groundtruth, pred_rank_list, k):\n","    count = 0\n","    dcg = 0\n","    for pred in pred_rank_list:\n","        if count >= k:\n","            break\n","        if groundtruth[pred] == 1:\n","            dcg += (1) / math.log2(count + 1 + 1)\n","        count += 1\n","\n","    return dcg\n","\n","\n","def get_NDCG(groundtruth, pred_rank_list, k):\n","    count = 0\n","    dcg = 0\n","    for pred in pred_rank_list:\n","        if count >= k:\n","            break\n","        if groundtruth[pred] == 1:\n","            dcg += (1) / math.log2(count + 1 + 1)\n","        count += 1\n","    idcg = 0\n","    num_real_item = np.sum(groundtruth)\n","    num_item = int(min(num_real_item, k))\n","    for i in range(num_item):\n","        idcg += (1) / math.log2(i + 1 + 1)\n","    ndcg = dcg / idcg\n","    return ndcg\n","\n","\n","def get_HT(groundtruth, pred_rank_list, k):\n","    count = 0\n","    for pred in pred_rank_list:\n","        if count >= k:\n","            break\n","        if groundtruth[pred] == 1:\n","            return 1\n","        count += 1\n","\n","    return 0"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"icsVwvODYL4q","executionInfo":{"status":"ok","timestamp":1624447965955,"user_tz":-120,"elapsed":7,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super(EncoderRNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.reduction = nn.Linear(input_size, hidden_size)\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.time_embedding = nn.Embedding(input_size, hidden_size)\n","        self.time_weight = nn.Linear(input_size, input_size)\n","        if use_embedding or use_linear_reduction:\n","            self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n","        else:\n","            self.gru = nn.GRU(input_size, hidden_size, num_layers)\n","\n","    def forward(self, input, hidden):\n","        if use_embedding:\n","            list = Variable(torch.LongTensor(input).view(-1, 1))\n","            if use_cuda:\n","                list = list.cuda()\n","            average_embedding = Variable(torch.zeros(hidden_size)).view(1, 1, -1)\n","            # sum_embedding = Variable(torch.zeros(hidden_size)).view(1,1,-1)\n","            vectorized_input = Variable(torch.zeros(self.input_size)).view(-1)\n","            if use_cuda:\n","                average_embedding = average_embedding.cuda()\n","                # sum_embedding = sum_embedding.cuda()\n","                vectorized_input = vectorized_input.cuda()\n","\n","            for ele in list:\n","                embedded = self.embedding(ele).view(1, 1, -1)\n","                tmp = average_embedding.clone()\n","                average_embedding = tmp + embedded\n","                # embedded = self.time_embedding(ele).view(1, 1, -1)\n","                # tmp = sum_embedding.clone()\n","                # sum_embedding = tmp + embedded\n","                vectorized_input[ele] = 1\n","\n","            # normalize_length = Variable(torch.LongTensor(len(idx_list)))\n","            # if use_cuda:\n","            #     normalize_length = normalize_length.cuda()\n","            if use_average_embedding:\n","                tmp = [1] * hidden_size\n","                length = Variable(torch.FloatTensor(tmp))\n","                if use_cuda:\n","                    length = length.cuda()\n","                # for idx in range(hidden_size):\n","                real_ave = average_embedding.view(-1) / length\n","                average_embedding = real_ave.view(1, 1, -1)\n","\n","            embedding = average_embedding\n","        else:\n","            tensorized_input = torch.from_numpy(input).clone().type(torch.FloatTensor)\n","            inputs = Variable(torch.unsqueeze(tensorized_input, 0).view(1, -1))\n","            if use_cuda:\n","                inputs = inputs.cuda()\n","            if use_linear_reduction == 1:\n","                reduced_input = self.reduction(inputs)\n","            else:\n","                reduced_input = inputs\n","\n","            embedding = torch.unsqueeze(reduced_input, 0)\n","\n","        output, hidden = self.gru(embedding, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        result = Variable(torch.zeros(num_layers, 1, self.hidden_size))\n","        if use_cuda:\n","            return result.cuda()\n","        else:\n","            return result\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"kadWJ7qPYNVe","executionInfo":{"status":"ok","timestamp":1624447965955,"user_tz":-120,"elapsed":6,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, num_layers, dropout_p=0.2, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        if use_embedding or use_linear_reduction:\n","            self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","            self.attn1 = nn.Linear(self.hidden_size + output_size, self.hidden_size)\n","        else:\n","            self.attn = nn.Linear(self.hidden_size + self.output_size, self.output_size)\n","\n","        if use_embedding or use_linear_reduction:\n","            self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","            self.attn_combine3 = nn.Linear(self.hidden_size * 2 + output_size, self.hidden_size)\n","        else:\n","            self.attn_combine = nn.Linear(self.hidden_size + self.output_size, self.hidden_size)\n","        self.attn_combine5 = nn.Linear(self.output_size, self.output_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.reduction = nn.Linear(self.output_size, self.hidden_size)\n","        if use_embedding or use_linear_reduction:\n","            self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n","        else:\n","            self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs, history_record, last_hidden):\n","        if use_embedding:\n","            list = Variable(torch.LongTensor(input).view(-1, 1))\n","            if use_cuda:\n","                list = list.cuda()\n","            average_embedding = Variable(torch.zeros(hidden_size)).view(1, 1, -1)\n","            if use_cuda:\n","                average_embedding = average_embedding.cuda()\n","\n","            for ele in list:\n","                embedded = self.embedding(ele).view(1, 1, -1)\n","                tmp = average_embedding.clone()\n","                average_embedding = tmp + embedded\n","\n","            if use_average_embedding:\n","                tmp = [1] * hidden_size\n","                length = Variable(torch.FloatTensor(tmp))\n","                if use_cuda:\n","                    length = length.cuda()\n","                # for idx in range(hidden_size):\n","                real_ave = average_embedding.view(-1) / length\n","                average_embedding = real_ave.view(1, 1, -1)\n","\n","            embedding = average_embedding\n","        else:\n","            tensorized_input = torch.from_numpy(input).clone().type(torch.FloatTensor)\n","            inputs = Variable(torch.unsqueeze(tensorized_input, 0).view(1, -1))\n","            if use_cuda:\n","                inputs = inputs.cuda()\n","            if use_linear_reduction == 1:\n","                reduced_input = self.reduction(inputs)\n","            else:\n","                reduced_input = inputs\n","\n","            embedding = torch.unsqueeze(reduced_input, 0)\n","\n","        if use_dropout:\n","            droped_ave_embedded = self.dropout(embedding)\n","        else:\n","            droped_ave_embedded = embedding\n","\n","        history_context = Variable(torch.FloatTensor(history_record).view(1, -1))\n","        if use_cuda:\n","            history_context = history_context.cuda()\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((droped_ave_embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        element_attn_weights = F.softmax(\n","            self.attn1(torch.cat((history_context, hidden[0]), 1)), dim=1)\n","\n","        # attn_applied = torch.bmm(element_attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n","\n","        # attn_embedd = element_attn_weights * droped_ave_embedded[0]\n","\n","        output = torch.cat((droped_ave_embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","        # output = torch.cat((droped_ave_embedded[0], attn_applied[0], time_coef.unsqueeze(0)), 1)\n","        # output = self.attn_combine3(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        linear_output = self.out(output[0])\n","        # output_user_item = F.softmax(linear_output)\n","\n","        value = torch.sigmoid(self.attn_combine5(history_context).unsqueeze(0))\n","\n","        one_vec = Variable(torch.ones(self.output_size).view(1, -1))\n","        if use_cuda:\n","            one_vec = one_vec.cuda()\n","\n","        # ones_set = torch.index_select(value[0,0], 1, ones_idx_set[:, 1])\n","        res = history_context.clone()\n","        res[history_context != 0] = 1\n","\n","        # output = F.softmax(linear_output * (one_vec - res * value[0]) + history_context * value[0], dim=1)\n","        output = F.softmax(linear_output, dim=1)\n","\n","        return output.view(1, -1), hidden, attn_weights\n","\n","    def initHidden(self):\n","        result = Variable(torch.zeros(num_layers, 1, self.hidden_size))\n","        if use_cuda:\n","            return result.cuda()\n","        else:\n","            return result"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"TwOHVcDAYX7R","executionInfo":{"status":"ok","timestamp":1624447965956,"user_tz":-120,"elapsed":6,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["class custom_MultiLabelLoss_torch(nn.modules.loss._Loss):\n","    def __init__(self):\n","        super(custom_MultiLabelLoss_torch, self).__init__()\n","\n","    def forward(self, pred, target, weights):\n","        mseloss = torch.sum(weights * torch.pow((pred - target), 2))\n","        pred = pred.data\n","        target = target.data\n","        \n","        ones_idx_set = (target == 1).nonzero()\n","        zeros_idx_set = (target == 0).nonzero()\n","        \n","        ones_set = torch.index_select(pred, 1, ones_idx_set[:, 1])\n","        zeros_set = torch.index_select(pred, 1, zeros_idx_set[:, 1])\n","        \n","        repeat_ones = ones_set.repeat(1, zeros_set.shape[1])\n","        repeat_zeros_set = torch.transpose(zeros_set.repeat(ones_set.shape[1], 1), 0, 1).clone()\n","        repeat_zeros = repeat_zeros_set.reshape(1, -1)\n","        difference_val = -(repeat_ones - repeat_zeros)\n","        exp_val = torch.exp(difference_val)\n","        exp_loss = torch.sum(exp_val)\n","        normalized_loss = exp_loss / (zeros_set.shape[1] * ones_set.shape[1])\n","        set_loss = Variable(torch.FloatTensor([labmda * normalized_loss]), requires_grad=True)\n","        if use_cuda:\n","            set_loss = set_loss.cuda()\n","        loss = mseloss + set_loss\n","        # loss = mseloss\n","        return loss"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyTJ96N_Y3k_","executionInfo":{"status":"ok","timestamp":1624447965957,"user_tz":-120,"elapsed":7,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["def train(input_variable, target_variable, encoder, decoder, codes_inverse_freq, encoder_optimizer, decoder_optimizer,\n","          criterion, output_size, next_k_step, update_params, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = len(input_variable)\n","    target_length = len(target_variable)\n","\n","    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n","    if use_cuda:\n","        encoder_outputs = encoder_outputs.cuda()\n","\n","    loss = 0\n","\n","    history_record = np.zeros(output_size)\n","    for ei in range(input_length - 1):\n","        if ei == 0:\n","            continue\n","        for ele in input_variable[ei]:\n","            history_record[ele] += 1 / (input_length - 2)\n","\n","    for ei in range(input_length - 1):\n","        if ei == 0:\n","            continue\n","        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n","        encoder_outputs[ei - 1] = encoder_output[0][0]\n","\n","    last_input = input_variable[input_length - 2]\n","    decoder_hidden = encoder_hidden\n","    last_hidden = encoder_hidden\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    topk = 1\n","\n","    decoder_input = last_input\n","    for di in range(next_k_step):\n","\n","        if atten_decoder:\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs, history_record, last_hidden)\n","        else:\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden)\n","        topv, topi = decoder_output.data.topk(topk)\n","        ni = topi[0][0]\n","\n","        # activation_bound\n","        # topk_labels\n","        # target_neg = zero2neg(target_variable[di])\n","\n","        vectorized_target = np.zeros(output_size)\n","        for idx in target_variable[di + 1]:\n","            vectorized_target[idx] = 1\n","\n","        target = Variable(torch.FloatTensor(vectorized_target).view(1, -1))\n","        if use_cuda:\n","            target = target.cuda()\n","        weights = Variable(torch.FloatTensor(codes_inverse_freq).view(1, -1))\n","        if use_cuda:\n","            weights = weights.cuda()\n","        tt = criterion(decoder_output, target, weights)\n","        # tt = criterion(decoder_output, target)\n","        # tt = torch.sum(weights*torch.pow((decoder_output - target),2))\n","        loss += tt\n","        decoder_input = target_variable[di + 1]\n","        # loss += multilable_loss(decoder_output, target)\n","\n","    # encoder_optimizer.zero_grad()\n","    # decoder_optimizer.zero_grad()\n","    if update_params:\n","        loss.backward()\n","\n","        encoder_optimizer.step()\n","        decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFN6BTSQY_Qd","executionInfo":{"status":"ok","timestamp":1624447966406,"user_tz":-120,"elapsed":455,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["def custom_after_subplot(ax: plt.Axes, group: str, x_label: str):\n","    if group == 'folds':\n","        ax.set_xlabel(\"fold\")\n","    if group == 'epochs':\n","        ax.set_xlabel(\"epochs\")\n","   \n","\n","def trainIters(folds, output_size, encoder, decoder, model_id, weights,\n","                       next_k_step, n_iters, print_every=300):\n","    start = time.time()\n","    full_training_losses = []\n","    full_validation_losses = []\n","\n","    epoch_metrics = {}\n","    fold_metrics = {}\n","\n","\n","    if optimizer_option == 1:\n","        encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","        decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    elif optimizer_option == 2:\n","        # encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-09, weight_decay=0)\n","        # encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate, betas=(0.88, 0.95), eps=1e-08, weight_decay=0)\n","        encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-11,\n","                                             weight_decay=0)\n","        decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-11,\n","                                             weight_decay=0)\n","    elif optimizer_option == 3:\n","        encoder_optimizer = torch.optim.RMSprop(encoder.parameters(), lr=learning_rate, alpha=0.99, eps=1e-08,\n","                                                weight_decay=0, momentum=0, centered=False)\n","        decoder_optimizer = torch.optim.RMSprop(decoder.parameters(), lr=learning_rate, alpha=0.99, eps=1e-08,\n","                                                weight_decay=0, momentum=0, centered=False)\n","    elif optimizer_option == 4:\n","        encoder_optimizer = torch.optim.Adadelta(encoder.parameters(), lr=learning_rate, rho=0.9, eps=1e-06,\n","                                                 weight_decay=0)\n","        decoder_optimizer = torch.optim.Adadelta(decoder.parameters(), lr=learning_rate, rho=0.9, eps=1e-06,\n","                                                 weight_decay=0)\n","    \n","    total_iter = 0\n","\n","    criterion = custom_MultiLabelLoss_torch()\n","    # criterion = nn.MSELoss()\n","    # criterion = nn.NLLLoss()\n","    # criterion = nn.MultiLabelSoftMarginLoss(size_average=False)\n","    # criterion = nn.BCELoss()\n","\n","    for j in range(n_iters):\n","        logs = {}\n","        training_loss_total = 0.0\n","        validation_loss_total = 0.0\n","        validation_recall_total = 0.0\n","        validation_precision_total = 0.0\n","        validation_f1_total = 0.0\n","        validation_ndcg_total = 0.0\n","        validation_hr_total = 0.0\n","\n","        for fold_index, fold in enumerate(folds):           \n","            print(\"Epoch:\", j, \"Fold:\", fold_index)\n","            training_loss = 0.0\n","            validation_loss = 0.0\n","            X_train, y_train = fold[0][0], fold[0][1]\n","            X_val, y_val = fold[1][0], fold[1][1]\n","\n","            # Training set\n","            for iter in range(len(y_train)):\n","                # print('Train iter ', iter, ' out of ', len(y_train)) if iter % 100 == 0 else 0\n","                input_variable = X_train[iter] # past sequence\n","                target_variable = y_train[iter] # future sequence\n","\n","                loss = train(input_variable, target_variable, encoder,\n","                            decoder, weights, encoder_optimizer, decoder_optimizer, criterion, output_size,\n","                            next_k_step, update_params=True)\n","                training_loss_total += loss\n","                training_loss += loss\n","                full_training_losses.append(loss)\n","\n","                total_iter += 1\n","            print('Fold avg train loss: ' + str(training_loss / len(y_train)))\n","            \n","            # logs['fold_loss'] = training_loss / (len(y_train))\n","\n","            # Validation set\n","            with torch.no_grad():\n","                # Calculate metrics for this fold's validation set\n","                recall, ndcg, hr, prec, f1 = evaluate(X_val, y_val, encoder, decoder, output_size, next_k_step, 5) \n","                print('Fold avg val recall:' + str(recall))\n","                print('Fold avg val precision:' + str(prec))\n","                print('Fold avg val f1:' + str(f1))\n","                print('Fold avg val ndcg:' + str(ndcg))\n","                print('Fold avg val hr:' + str(hr))\n","                validation_recall_total += recall\n","                validation_precision_total += prec\n","                validation_f1_total += f1\n","                validation_ndcg_total += ndcg\n","                validation_hr_total += hr\n","                \n","                for iter in range(len(y_val)):\n","                    # print('Validation iter ', iter, ' out of ', len(y_val)) if iter % 100 == 0 else 0\n","                    input_variable = X_val[iter] # past sequence\n","                    target_variable = y_val[iter] # future sequence\n","\n","                    loss = train(input_variable, target_variable, encoder,\n","                                decoder, weights, encoder_optimizer, decoder_optimizer, criterion, output_size,\n","                                next_k_step, update_params=False)\n","                    validation_loss_total += loss\n","                    validation_loss += loss\n","                    full_validation_losses.append(loss)\n","                print('Fold avg val loss: ' + str(validation_loss / len(y_val)))\n","\n","\n","        # Metrics per epoch\n","        training_loss_avg = training_loss_total / (len(folds) * len(y_train))\n","        validation_loss_avg = validation_loss_total / (len(folds) * len(y_val))\n","        validation_recall_avg = validation_recall_total / (len(folds))\n","        validation_precision_avg = validation_precision_total / (len(folds))\n","        validation_f1_avg = validation_f1_total / (len(folds))\n","        validation_ndcg_avg = validation_ndcg_total / (len(folds))\n","        validation_hr_avg = validation_hr_total / (len(folds))\n","\n","        print('%s (%d %d%%) train %.6f val %.6f' % (timeSince(start, total_iter / (n_iters *  len(folds) * len(y_train))), total_iter, total_iter / (n_iters *  len(folds) * len(y_train)) * 100,training_loss_avg, validation_loss_avg))\n","\n","        print('Epoch avg val recall:' + str(validation_recall_avg))\n","        print('Epoch avg val precision:' + str(validation_precision_avg))\n","        print('Epoch avg val f1:' + str(validation_f1_avg))\n","        print('Epoch avg val ndcg:' + str(validation_ndcg_avg))\n","        print('Epoch avg val hr:' + str(validation_hr_avg))\n","        # lc = pd.DataFrame({\"loss\": full_training_losses})\n","        # lc.plot(lw=2, title=\"training loss\");\n","        # plt.xlabel('iterations');\n","\n","        filepath = './models/encoder' + (model_id) + '_model_epoch' + str(int(j))\n","        torch.save(encoder, filepath)\n","        filepath = './models/decoder' + (model_id) + '_model_epoch' + str(int(j))\n","        torch.save(decoder, filepath)\n","        print('Finish epoch: ' + str(j))\n","        print('Model is saved.')\n","        sys.stdout.flush()\n","    # showPlot(plot_losses)\n","    # print('The loss: ' + str(print_loss_total))\n","\n","\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8nG8mdIZDG2","executionInfo":{"status":"ok","timestamp":1624447966406,"user_tz":-120,"elapsed":2,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["cosine_sim = []\n","pair_cosine_sim = []\n","\n","\n","def decoding_next_k_step(encoder, decoder, input_variable, target_variable, output_size, k, num_set_elements):\n","    encoder_hidden = encoder.initHidden()\n","\n","    input_length = len(input_variable)\n","    encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n","    if use_cuda:\n","        encoder_outputs = encoder_outputs.cuda()\n","\n","    loss = 0\n","\n","    history_record = np.zeros(output_size)\n","    count = 0\n","    for ei in range(input_length - 1):\n","        if ei == 0:\n","            continue\n","        for ele in input_variable[ei]:\n","            history_record[ele] += 1\n","        count += 1\n","\n","    history_record = history_record / count\n","\n","    for ei in range(input_length - 1):\n","        if ei == 0:\n","            continue\n","        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n","        encoder_outputs[ei - 1] = encoder_output[0][0]\n","\n","        for ii in range(k):\n","            vectorized_target = np.zeros(output_size)\n","            for idx in target_variable[ii + 1]:\n","                vectorized_target[idx] = 1\n","\n","            vectorized_input = np.zeros(output_size)\n","            for idx in input_variable[ei]:\n","                vectorized_input[idx] = 1\n","\n","    decoder_input = input_variable[input_length - 2]\n","\n","    decoder_hidden = encoder_hidden\n","    last_hidden = decoder_hidden\n","    # Without teacher forcing: use its own predictions as the next input\n","    num_str = 0\n","    topk = 400\n","    decoded_vectors = []\n","    prob_vectors = []\n","    cout = 0\n","    for di in range(k):\n","        if atten_decoder:\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs, history_record, last_hidden)\n","        else:\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden)\n","        topv, topi = decoder_output.data.topk(topk)\n","        ni = topi[0][0]\n","\n","        vectorized_target = np.zeros(output_size)\n","        for idx in target_variable[di + 1]:\n","            vectorized_target[idx] = 1\n","\n","        # target_topi = vectorized_target.argsort()[::-1][:topk]\n","        # activation_bound\n","\n","        count = 0\n","        start_idx = -1\n","        end_idx = output_size\n","        if num_set_elements > 0:\n","            pick_num = num_set_elements\n","        else:\n","            pick_num = np.sum(vectorized_target)\n","            # print(pick_num)\n","\n","        tmp = []\n","        for ele in range(len(topi[0])):\n","            if count >= pick_num:\n","                break\n","            tmp.append(topi[0][ele])\n","            count += 1\n","\n","        decoded_vectors.append(tmp)\n","        decoder_input = tmp\n","        tmp = []\n","        for i in range(topk):\n","            tmp.append(topi[0][i])\n","        prob_vectors.append(tmp)\n","\n","    return decoded_vectors, prob_vectors\n","\n","\n","# def vectorized2set(vector, set):\n","#     print('vector length', len(vector))\n","#     i in range(len(vector)):\n","#         if vector[i] == 1:\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"zMejY92aZMdJ","executionInfo":{"status":"ok","timestamp":1624449023511,"user_tz":-120,"elapsed":500,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["def evaluate(X_test, y_test, encoder, decoder, output_size, next_k_step, num_set_elements):\n","    prec = []\n","    rec = []\n","    F = []\n","    prec1 = []\n","    rec1 = []\n","    F1 = []\n","    prec2 = []\n","    rec2 = []\n","    F2 = []\n","    prec3 = []\n","    rec3 = []\n","    F3 = []\n","    length = np.zeros(3)\n","\n","    NDCG = []\n","    n_hit = 0\n","    count = 0\n","\n","    for iter in range(len(y_test)):\n","        input_variable = X_test[iter]\n","        target_variable = y_test[iter]\n","\n","        count += 1\n","        output_vectors, prob_vectors = decoding_next_k_step(encoder, decoder, input_variable, target_variable,\n","                                                            output_size, next_k_step, num_set_elements)\n","        hit = 0\n","        # for each set\n","        for idx in range(len(output_vectors)):\n","            # for idx in [2]:\n","\n","\n","\n","            vectorized_target = np.zeros(output_size)\n","            for ii in target_variable[1 + idx]:\n","                vectorized_target[ii] = 1\n","\n","            vectorized_output = np.zeros(output_size)\n","            prediction = [int(t.item()) for t in output_vectors[idx]]\n","            for ii in output_vectors[idx]:\n","                vectorized_output[ii] = 1\n","\n","            precision, recall, Fscore, correct = get_precision_recall_Fscore(vectorized_target, vectorized_output)\n","            \n","            prec.append(precision)\n","            rec.append(recall)\n","            F.append(Fscore)\n","            if idx == 0:\n","                prec1.append(precision)\n","                rec1.append(recall)\n","                F1.append(Fscore)\n","            elif idx == 1:\n","                prec2.append(precision)\n","                rec2.append(recall)\n","                F2.append(Fscore)\n","            elif idx == 2:\n","                prec3.append(precision)\n","                rec3.append(recall)\n","                F3.append(Fscore)\n","            length[idx] += np.sum(target_variable[1 + idx])\n","            target_topi = prob_vectors[idx]\n","            HT = get_HT(vectorized_target, target_topi, num_set_elements) # either a 1 or a 0 if all elements in set are correct?\n","            hit += HT\n","            ndcg = get_NDCG(vectorized_target, target_topi, num_set_elements)\n","            NDCG.append(ndcg)\n","\n","            # print(idx + 1, 'out of', len(output_vectors))\n","            # print('ground truth', target_variable[1 + idx])\n","            # print('prediction', prediction)\n","            # print('recall: %s, precision: %s, f1: %s, correct: %s, ndcg: %s, HT: %s' % (recall, precision, Fscore, correct, ndcg, HT))\n","        if hit == next_k_step:\n","            n_hit += 1\n","\n","\n","    print('average precision of subsequent sets' + ': ' + str(np.mean(prec)) + ' with std: ' + str(np.std(prec)))\n","    print('average recall' + ': ' + str(np.mean(rec)) + ' with std: ' + str(np.std(rec)))\n","    print('average F score of subsequent sets' + ': ' + str(np.mean(F)) + ' with std: ' + str(np.std(F)))\n","    print('average NDCG: ' + str(np.mean(NDCG)))\n","    print('average hit rate: ' + str(n_hit / len(y_test)))\n","\n","    # print('average precision of 1st' + ': ' + str(np.mean(prec1)) + ' with std: ' + str(np.std(prec1)))\n","    # print('average recall of 1st' + ': ' + str(np.mean(rec1)) + ' with std: ' + str(np.std(rec1)))\n","    # print('average F score of 1st' + ': ' + str(np.mean(F1)) + ' with std: ' + str(np.std(F1)))\n","    # print('average precision of 2nd' + ': ' + str(np.mean(prec2)) + ' with std: ' + str(np.std(prec2)))\n","    # print('average recall of 2nd' + ': ' + str(np.mean(rec2)) + ' with std: ' + str(np.std(rec2)))\n","    # print('average F score of 2nd' + ': ' + str(np.mean(F2)) + ' with std: ' + str(np.std(F2)))\n","    # print('average precision of 3rd' + ': ' + str(np.mean(prec3)) + ' with std: ' + str(np.std(prec3)))\n","    # print('average recall of 3rd' + ': ' + str(np.mean(rec3)) + ' with std: ' + str(np.std(rec3)))\n","    # print('average F score of 3rd' + ': ' + str(np.mean(F3)) + ' with std: ' + str(np.std(F3)))\n","\n","    return np.mean(rec), np.mean(NDCG), n_hit / len(y_test), np.mean(prec), np.mean(F)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-k2-1WTx-8I","executionInfo":{"status":"ok","timestamp":1624447966724,"user_tz":-120,"elapsed":5,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["def evaluate_random_prediction(y_test, output_size, next_k_step, num_set_elements):\n","    prec = []\n","    rec = []\n","    F = []\n","    prec1 = []\n","    rec1 = []\n","    F1 = []\n","    prec2 = []\n","    rec2 = []\n","    F2 = []\n","    prec3 = []\n","    rec3 = []\n","    F3 = []\n","    length = np.zeros(3)\n","\n","    NDCG = []\n","    n_hit = 0\n","    count = 0\n","\n","    for iter in range(len(y_test)):\n","        target_variable = y_test[iter]\n","\n","        count += 1\n","        hit = 0\n","        # for each set\n","        for idx in range(next_k_step):\n","            # for idx in [2]:\n","            vectorized_target = np.zeros(output_size)\n","            for ii in target_variable[1 + idx]:\n","                vectorized_target[ii] = 1\n","\n","            # random\n","            vectorized_output = np.zeros(output_size)\n","            vectorized_output[:num_set_elements] = 1\n","            np.random.shuffle(vectorized_output)\n","\n","            precision, recall, Fscore, correct = get_precision_recall_Fscore(vectorized_target, vectorized_output)\n","            prec.append(precision)\n","            rec.append(recall)\n","            F.append(Fscore)\n","            if idx == 0:\n","                prec1.append(precision)\n","                rec1.append(recall)\n","                F1.append(Fscore)\n","            elif idx == 1:\n","                prec2.append(precision)\n","                rec2.append(recall)\n","                F2.append(Fscore)\n","            elif idx == 2:\n","                prec3.append(precision)\n","                rec3.append(recall)\n","                F3.append(Fscore)\n","            length[idx] += np.sum(target_variable[1 + idx])\n","            # target_topi = prob_vectors[idx]\n","            # hit += get_HT(vectorized_target, target_topi, num_set_elements) # either a 1 or a 0 if all elements in set are correct?\n","            # ndcg = get_NDCG(vectorized_target, target_topi, num_set_elements)\n","            # NDCG.append(ndcg)\n","        if hit == next_k_step:\n","            n_hit += 1\n","\n","\n","    print('average precision of subsequent sets' + ': ' + str(np.mean(prec)) + ' with std: ' + str(np.std(prec)))\n","    print('average recall' + ': ' + str(np.mean(rec)) + ' with std: ' + str(np.std(rec)))\n","    print('average F score of subsequent sets' + ': ' + str(np.mean(F)) + ' with std: ' + str(np.std(F)))\n","    # print('average precision of 1st' + ': ' + str(np.mean(prec1)) + ' with std: ' + str(np.std(prec1)))\n","    # print('average recall of 1st' + ': ' + str(np.mean(rec1)) + ' with std: ' + str(np.std(rec1)))\n","    # print('average F score of 1st' + ': ' + str(np.mean(F1)) + ' with std: ' + str(np.std(F1)))\n","    # print('average precision of 2nd' + ': ' + str(np.mean(prec2)) + ' with std: ' + str(np.std(prec2)))\n","    # print('average recall of 2nd' + ': ' + str(np.mean(rec2)) + ' with std: ' + str(np.std(rec2)))\n","    # print('average F score of 2nd' + ': ' + str(np.mean(F2)) + ' with std: ' + str(np.std(F2)))\n","    # print('average precision of 3rd' + ': ' + str(np.mean(prec3)) + ' with std: ' + str(np.std(prec3)))\n","    # print('average recall of 3rd' + ': ' + str(np.mean(rec3)) + ' with std: ' + str(np.std(rec3)))\n","    # print('average F score of 3rd' + ': ' + str(np.mean(F3)) + ' with std: ' + str(np.std(F3)))\n","    print('average NDCG: ' + str(np.mean(NDCG)))\n","    print('average hit rate: ' + str(n_hit / len(y_test)))\n","    return np.mean(rec), np.mean(NDCG), n_hit / len(y_test), np.mean(prec), np.mean(F)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5rNWghj1ECs","executionInfo":{"status":"ok","timestamp":1624447966724,"user_tz":-120,"elapsed":4,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["def evaluate_top_frequent_prediction(y_test, output_size, next_k_step, num_set_elements, most_frequent_elements):\n","    prec = []\n","    rec = []\n","    F = []\n","    prec1 = []\n","    rec1 = []\n","    F1 = []\n","    prec2 = []\n","    rec2 = []\n","    F2 = []\n","    prec3 = []\n","    rec3 = []\n","    F3 = []\n","    length = np.zeros(3)\n","\n","    NDCG = []\n","    n_hit = 0\n","    count = 0\n","\n","    for iter in range(len(y_test)):\n","        target_variable = y_test[iter]\n","\n","        count += 1\n","        hit = 0\n","        # for each set\n","        for idx in range(next_k_step):\n","            # for idx in [2]:\n","            vectorized_target = np.zeros(output_size)\n","            for ii in target_variable[1 + idx]:\n","                vectorized_target[ii] = 1\n","            \n","            # top frequent prediction\n","            vectorized_output = np.zeros(output_size)\n","            for ii in most_frequent_elements:\n","                vectorized_output[ii] = 1\n","\n","\n","            precision, recall, Fscore, correct = get_precision_recall_Fscore(vectorized_target, vectorized_output)\n","            prec.append(precision)\n","            rec.append(recall)\n","            F.append(Fscore)\n","            if idx == 0:\n","                prec1.append(precision)\n","                rec1.append(recall)\n","                F1.append(Fscore)\n","            elif idx == 1:\n","                prec2.append(precision)\n","                rec2.append(recall)\n","                F2.append(Fscore)\n","            elif idx == 2:\n","                prec3.append(precision)\n","                rec3.append(recall)\n","                F3.append(Fscore)\n","            length[idx] += np.sum(target_variable[1 + idx])\n","            # target_topi = prob_vectors[idx]\n","            # hit += get_HT(vectorized_target, target_topi, num_set_elements) # either a 1 or a 0 if all elements in set are correct?\n","            # ndcg = get_NDCG(vectorized_target, target_topi, num_set_elements)\n","            # NDCG.append(ndcg)\n","        if hit == next_k_step:\n","            n_hit += 1\n","\n","\n","    print('average precision of subsequent sets' + ': ' + str(np.mean(prec)) + ' with std: ' + str(np.std(prec)))\n","    print('average recall' + ': ' + str(np.mean(rec)) + ' with std: ' + str(np.std(rec)))\n","    print('average F score of subsequent sets' + ': ' + str(np.mean(F)) + ' with std: ' + str(np.std(F)))\n","    # print('average precision of 1st' + ': ' + str(np.mean(prec1)) + ' with std: ' + str(np.std(prec1)))\n","    # print('average recall of 1st' + ': ' + str(np.mean(rec1)) + ' with std: ' + str(np.std(rec1)))\n","    # print('average F score of 1st' + ': ' + str(np.mean(F1)) + ' with std: ' + str(np.std(F1)))\n","    # print('average precision of 2nd' + ': ' + str(np.mean(prec2)) + ' with std: ' + str(np.std(prec2)))\n","    # print('average recall of 2nd' + ': ' + str(np.mean(rec2)) + ' with std: ' + str(np.std(rec2)))\n","    # print('average F score of 2nd' + ': ' + str(np.mean(F2)) + ' with std: ' + str(np.std(F2)))\n","    # print('average precision of 3rd' + ': ' + str(np.mean(prec3)) + ' with std: ' + str(np.std(prec3)))\n","    # print('average recall of 3rd' + ': ' + str(np.mean(rec3)) + ' with std: ' + str(np.std(rec3)))\n","    # print('average F score of 3rd' + ': ' + str(np.mean(F3)) + ' with std: ' + str(np.std(F3)))\n","    print('average NDCG: ' + str(np.mean(NDCG)))\n","    print('average hit rate: ' + str(n_hit / len(y_test)))\n","    return np.mean(rec), np.mean(NDCG), n_hit / len(y_test), np.mean(prec), np.mean(F)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"j2iszEAaklYO","executionInfo":{"status":"ok","timestamp":1624447966724,"user_tz":-120,"elapsed":3,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["def evaluate_repeat_prediction(y_test, output_size, next_k_step, num_set_elements):\n","    prec = []\n","    rec = []\n","    F = []\n","    prec1 = []\n","    rec1 = []\n","    F1 = []\n","    prec2 = []\n","    rec2 = []\n","    F2 = []\n","    prec3 = []\n","    rec3 = []\n","    F3 = []\n","    length = np.zeros(3)\n","\n","    NDCG = []\n","    n_hit = 0\n","    count = 0\n","\n","    for iter in range(len(y_test)):\n","        target_variable = y_test[iter]\n","\n","        previous = [1, 2, 3, 4, 5] if iter == 0 else y_test[iter-1]\n","\n","        count += 1\n","        hit = 0\n","        # for each set\n","        for idx in range(next_k_step):\n","            # for idx in [2]:\n","            vectorized_target = np.zeros(output_size)\n","            for ii in target_variable[1 + idx]:\n","                vectorized_target[ii] = 1\n","            \n","            # prediction = previous set\n","            vectorized_output = np.zeros(output_size)\n","            for ii in previous:\n","                vectorized_output[ii] = 1\n","\n","\n","            precision, recall, Fscore, correct = get_precision_recall_Fscore(vectorized_target, vectorized_output)\n","            prec.append(precision)\n","            rec.append(recall)\n","            F.append(Fscore)\n","            if idx == 0:\n","                prec1.append(precision)\n","                rec1.append(recall)\n","                F1.append(Fscore)\n","            elif idx == 1:\n","                prec2.append(precision)\n","                rec2.append(recall)\n","                F2.append(Fscore)\n","            elif idx == 2:\n","                prec3.append(precision)\n","                rec3.append(recall)\n","                F3.append(Fscore)\n","            length[idx] += np.sum(target_variable[1 + idx])\n","            # target_topi = prob_vectors[idx]\n","            # hit += get_HT(vectorized_target, target_topi, num_set_elements) # either a 1 or a 0 if all elements in set are correct?\n","            # ndcg = get_NDCG(vectorized_target, target_topi, num_set_elements)\n","            # NDCG.append(ndcg)\n","        if hit == next_k_step:\n","            n_hit += 1\n","\n","\n","    print('average precision of subsequent sets' + ': ' + str(np.mean(prec)) + ' with std: ' + str(np.std(prec)))\n","    print('average recall' + ': ' + str(np.mean(rec)) + ' with std: ' + str(np.std(rec)))\n","    print('average F score of subsequent sets' + ': ' + str(np.mean(F)) + ' with std: ' + str(np.std(F)))\n","\n","    print('average NDCG: ' + str(np.mean(NDCG)))\n","    print('average hit rate: ' + str(n_hit / len(y_test)))\n","    return np.mean(rec), np.mean(NDCG), n_hit / len(y_test), np.mean(prec), np.mean(F)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMqVAq07ZPA7","executionInfo":{"status":"ok","timestamp":1624447967189,"user_tz":-120,"elapsed":468,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["def load_data(path, history_file_name, future_file_name):\n","    print(\"Loading data from disk...\")\n","    freq_max = 200\n","    input_size = 5000\n","    X = []\n","    X_test = []\n","    X_frequency_init = np.zeros(input_size + 2)\n","\n","    set_sizes = []\n","    \n","    with open(path + \"data/\" + history_file_name, 'r') as csvfile:\n","        reader = csv.DictReader(csvfile)\n","        prevQueryId = currentQueryId = None\n","        tmp = []\n","        for i, row in enumerate(reader):\n","            if i == 0:\n","                prevQueryId = currentQueryId = row['queryId']\n","            currentQueryId = row['queryId']\n","            if currentQueryId != prevQueryId:\n","                X.append(np.sort(tmp))\n","                tmp = []\n","            tmp.append(int(row['partialQEPId']))\n","            \n","            set_sizes.append(len(tmp))\n","\n","            prevQueryId = currentQueryId\n","    \n","    print(\"X first 100:\", X[:100])\n","    print(\"X last 100:\", X[-100:])\n","\n","    with open(path + \"data/\" + future_file_name, 'r') as csvfile:\n","        reader = csv.DictReader(csvfile)\n","        prevQueryId = currentQueryId = None\n","        tmp = []\n","        for i, row in enumerate(reader):\n","            if i == 0:\n","                prevQueryId = currentQueryId = row['queryId']\n","            currentQueryId = row['queryId']\n","            if currentQueryId != prevQueryId:\n","                X_test.append(np.sort(tmp))\n","                tmp = []\n","            tmp.append(int(row['partialQEPId']))\n","            set_sizes.append(len(tmp))\n","            prevQueryId = currentQueryId\n","    print(\"X_test first 100:\", X_test[:100])\n","    print(\"X_test last 100:\", X_test[-100:])\n","\n","\n","    print(\"Maximum set size:\", max(set_sizes))\n","    print(\"Average set size:\", np.mean(set_sizes))\n","\n","    return X, X_test, input_size + 2, X_frequency_init\n","\n","def get_frequency_vector(X, X_dim):\n","    result_vector = np.zeros(X_dim, dtype=int)\n","    for i in X:\n","        result_vector[i] += 1\n","    return result_vector\n","\n","\n","def sliding_windows(X, seq_length, next_k_step):\n","    X_train = []\n","    y_train = []\n","\n","    for i in range(len(X)-(seq_length+next_k_step)):\n","        _X_train = [[-1], *X[i:(i+seq_length)]]\n","        _y_train = [[-1], *X[(i+seq_length):(i+seq_length+next_k_step)]]\n","        _X_train.append([-1])\n","        _y_train.append([-1])\n","        X_train.append(_X_train)\n","        y_train.append(_y_train)\n","\n","    return X_train, y_train\n","\n","def cv_split(X, n_folds, fold_size, seq_length, next_k_step):\n","    K = fold_size\n","    res = set()\n","    for _ in range(n_folds):\n","        temp = random.randint(0, len(X) - K) \n","        while any(temp >= idx and temp <= idx + K for idx in res):\n","            temp = random.randint(0, len(X) - K) \n","        res.add(temp)\n","    res = [(idx, idx + K) for idx in res]\n","\n","    print(\"The n_folds of non-overlapping random ranges are : \" + str(res))\n","\n","    # folds = [X[interval[0]:interval[1]] for interval in res]\n","\n","    # [(32611, 34611), (111787, 113787), (72365, 74365), (98960, 100960), (6677, 8677)]\n","\n","    folds = [X[13853:16853]] # for hyperparameter tuning, 1 fold, length 3000\n","    folds = [[fold[:int(len(fold)*0.8)], fold[int(len(fold)*0.8):]] for fold in folds]\n","\n","    result = []\n","    for fold in folds:\n","        fold_X_train, fold_y_train = sliding_windows(fold[0], seq_length, next_k_step)\n","        fold_X_val, fold_y_val = sliding_windows(fold[1], seq_length, next_k_step)\n","        result.append([[fold_X_train, fold_y_train], [fold_X_val, fold_y_val]])\n","    print(\"Number of training/validation folds:\", len(result))\n","    print(\"Number of training instances per fold:\", len(result[0][0][0])) # first fold, training, X\n","    print(\"Number of validation instances per fold:\", len(result[0][1][0])) # first fold, validation, X\n","    print(\"CV_split shape\", np.array(result).shape)\n","\n","\n","    return result\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"MiDyn9bpZgMq","executionInfo":{"status":"ok","timestamp":1624448542191,"user_tz":-120,"elapsed":699,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}}},"source":["def main():\n","    history_file_name, future_file_name = ['output_history_firstday_90.csv', 'output_future_firstday_90.csv']\n","    # history_file_name, future_file_name = ['iot_output_history.csv', 'iot_output_future.csv']\n","    model_version = 'Phonelabs_90_0.001'\n","    # model_version = 'iot_0.001'\n","    training = False # True for training mode, False for test mode\n","    path = './'\n","    directory = './models/'\n","\n","    seq_length = 10 # length of the input sequences we train on\n","    next_k_step = 2 # next k steps to predict\n","    n_folds = 3\n","    fold_size = 900\n","\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","    print(\"Seq_length: \" + str(seq_length) +\", Next_k_step: \" + str(next_k_step))\n","    print(\"n_folds: \" + str(n_folds) +\", fold_size: \" + str(fold_size))\n","    \n","    X, X_future, X_dim, X_frequency_init = load_data(path, history_file_name, future_file_name)\n","\n","    X_freq = get_frequency_vector(X, X_dim)\n","    print(\"X_freq\", X_freq)\n","    print(\"X_dim\", X_dim)\n","\n","\n","    # training_key_set, validation_key_set, test_key_set = partition_the_data_validate(data_chunk, list(data_chunk[future_chunk]), next_k_step)\n","\n","    weights = np.zeros(X_dim)\n","    max_freq = max(X_freq)\n","    \n","    print('Maximum feature frequency:', max_freq)\n","    for i in range(len(X_freq)):\n","        if X_freq[i] > 0:\n","            weights[i] = max_freq / X_freq[i]\n","        else:\n","            weights[i] = 0\n","\n","    print(\"Weights:\", weights)\n","\n","    folds = cv_split(X, n_folds, fold_size, seq_length, next_k_step)\n","\n","    # X_train, y_train = sliding_windows(X, seq_length, next_k_step)\n","\n","    X_test, y_test = sliding_windows(X_future, seq_length, next_k_step)\n","\n","    # print(\"train X  has:\", len(X_train) , \"series\")\n","    # print(\"train y  has:\", len(y_train) , \"series\")\n","\n","    # print(X_train[0])\n","    # print(y_train[0])\n","    # print(X_train[1])\n","    # print(y_train[1])\n","\n","    encoder1 = EncoderRNN(X_dim, hidden_size, num_layers)\n","    attn_decoder1 = AttnDecoderRNN(hidden_size, X_dim, num_layers, dropout_p=0.1)\n","\n","    if use_cuda:\n","        encoder1 = encoder1.cuda()\n","        attn_decoder1 = attn_decoder1.cuda()\n","\n","\n","\n","\n","    if training:\n","        if atten_decoder:\n","            trainIters(folds, X_dim, encoder1, attn_decoder1, model_version, weights,\n","                       next_k_step, num_iter, print_every=print_val)\n","\n","    else:\n","        for i in [5]: # number of elements predict for each set\n","            valid_recall = []\n","            valid_ndcg = []\n","            valid_hr = []\n","            valid_prec = []\n","            valid_f1 = []\n","            recall_list = []\n","            ndcg_list = []\n","            hr_list = []\n","            prec_list = []\n","            f1_list = []\n","            print('k = ' + str(i))\n","            for model_epoch in range(4):\n","                print('Epoch: ', model_epoch)\n","                encoder_pathes = './models/encoder' + str(model_version) + '_model_epoch' + str(model_epoch)\n","                decoder_pathes = './models/decoder' + str(model_version) + '_model_epoch' + str(model_epoch)\n","\n","                encoder_instance = torch.load(encoder_pathes)\n","                decoder_instance = torch.load(decoder_pathes)\n","\n","                # recall, ndcg, hr, prec, f1 = evaluate(X_train[-6000:], y_train[-6000:], encoder_instance, decoder_instance, X_dim, next_k_step, i)\n","                # valid_recall.append(recall)\n","                # valid_ndcg.append(ndcg)\n","                # valid_hr.append(hr)\n","                # valid_prec.append(prec)\n","                # valid_f1.append(f1)\n","\n","                recall, ndcg, hr, prec, f1  = evaluate(X_test[79034:84034], y_test[79034:84034], encoder_instance, decoder_instance, X_dim, next_k_step, i)\n","                \n","                # recall, ndcg, hr, prec, f1 = evaluate_random_prediction(y_test[79034:84034], X_dim, next_k_step, i)\n","\n","                \n","                # most_frequent_elements = X_freq.argsort()[::-1][:i]\n","                # recall, ndcg, hr, prec, f1 = evaluate_top_frequent_prediction(y_test[79034:84034], X_dim, next_k_step, i, most_frequent_elements)\n","\n","\n","                # recall, ndcg, hr, prec, f1 = evaluate_repeat_prediction(y_test[79034:84034], X_dim, next_k_step, i)\n","\n","                recall_list.append(recall)\n","                ndcg_list.append(ndcg)\n","                hr_list.append(hr)\n","                prec_list.append(prec)\n","                f1_list.append(f1)\n","            # valid_recall = np.asarray(valid_recall)\n","            # valid_ndcg = np.asarray(valid_ndcg)\n","            # valid_hr = np.asarray(valid_hr)\n","            # idx1 = valid_recall.argsort()[::-1][0]\n","            # idx2 = valid_ndcg.argsort()[::-1][0]\n","            # idx3 = valid_hr.argsort()[::-1][0]\n","            # print('max valid recall results:')\n","            # print('Epoch: ', idx1)\n","            # print('recall: ', recall_list[idx1])\n","            # print('ndcg: ', ndcg_list[idx1])\n","            # print('phr: ', hr_list[idx1])\n","\n","            # print('max valid ndcg results:')\n","            # print('Epoch: ', idx2)\n","            # print('recall: ', recall_list[idx2])\n","            # print('ndcg: ', ndcg_list[idx2])\n","            # print('phr: ', hr_list[idx2])\n","\n","            # print('max valid phr results:')\n","            # print('Epoch: ', idx3)\n","            # print('recall: ', recall_list[idx3])\n","            # print('ndcg: ', ndcg_list[idx3])\n","            # print('phr: ', hr_list[idx3])\n","\n","\n","            # print('Validation recall:', valid_recall)\n","            # print('Validation ndcg:', valid_ndcg)\n","            # print('Validation hit:', valid_hr)\n","            # print('Validation precision:', valid_prec)\n","            # print('Validation f1:', valid_f1)\n","            print('Test recall:', recall_list)\n","            print('Test ndcg:', ndcg_list)\n","            print('Test hit:', hr_list)\n","            print('Test precision:', prec_list)\n","            print('Test f1:', f1_list)\n","\n","\n","            lc = pd.DataFrame({\"Test recall\": recall_list, \"Test ndcg\": ndcg_list, \"Test hit\": hr_list, \"Test precision\": prec_list, \"Test f1\": f1_list})\n","            title = \"Test, k = \" + str(i)\n","            lc.plot(lw=2, title=title);\n","            plt.xlabel('epochs');\n","            print(title)\n","            print(lc.apply(minMax))"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXvqKVr8ZhYN","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1624449596546,"user_tz":-120,"elapsed":570128,"user":{"displayName":"Casper Siksma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBWNg-LIJSRsGFg-KH-8zFdztG9qjoiJIbOsd4kA=s64","userId":"09157385483834993232"}},"outputId":"a06f5d4d-4615-4547-c6e3-b5baadae3a3e"},"source":["main()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Seq_length: 10, Next_k_step: 2\n","n_folds: 3, fold_size: 900\n","Loading data from disk...\n","X first 100: [array([1]), array([ 87, 414]), array([ 272,  613, 2370]), array([42, 46, 47]), array([42, 46, 47]), array([ 87, 414]), array([272, 421]), array([ 707,  736,  927, 2104, 3543, 3585, 4389]), array([ 81, 738]), array([ 707,  736,  812, 1114, 1117, 1120, 1123, 1129, 1130]), array([770, 797, 798]), array([ 87, 678, 679]), array([ 87, 678, 679]), array([35, 40]), array([445, 447, 448]), array([445, 447, 448]), array([445, 447, 448]), array([445, 447, 448]), array([35, 40]), array([446, 627, 634]), array([446, 627, 634]), array([35, 40]), array([446, 627, 634]), array([35, 40]), array([35, 40]), array([35, 40]), array([272, 421]), array([272, 421]), array([35, 40]), array([272, 421]), array([807]), array([815, 818, 828]), array([702, 703, 705]), array([702, 703, 705]), array([445, 447, 448]), array([445, 447, 448]), array([445, 447, 448]), array([445, 447, 448]), array([445, 447, 448]), array([272, 421]), array([272, 421]), array([35, 40]), array([48, 78, 79, 80]), array([35, 48, 72, 73, 74, 75, 76, 77]), array([35, 40]), array([ 87, 555]), array([ 556,  557, 3969]), array([50, 51, 52]), array([50, 51, 52]), array([50, 51, 52]), array([50, 51, 52]), array([50, 51, 52]), array([50, 51, 52]), array([50, 51, 52]), array([50, 51, 52]), array([104, 401, 402]), array([104, 423, 424, 425, 426]), array([ 32,  41, 112, 113, 115, 468, 472, 473, 571, 664, 666, 669]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([900, 905, 918]), array([35, 40]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28])]\n","X last 100: [array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([17, 18, 19]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([29, 30, 31]), array([29, 30, 31]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([17, 18, 19]), array([ 87, 678, 679]), array([ 87, 678, 679]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([702, 703, 705]), array([702, 703, 705]), array([1, 2, 3]), array([445, 447, 448]), array([1, 2, 3]), array([445, 447, 448]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3])]\n","X_test first 100: [array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([ 32,  41, 112, 113, 115, 468, 472, 473, 571, 664, 666, 669]), array([1, 2, 3]), array([16, 20, 21, 22, 23, 24, 25]), array([1, 2, 3]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([1, 2, 3]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([1, 2, 3]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([1, 2, 3]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([1, 2, 3]), array([16, 20, 21, 22, 23, 24, 25]), array([1, 2, 3]), array([26, 27, 28]), array([1, 2, 3]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([1, 2, 3]), array([16, 20, 21, 22, 23, 24, 25]), array([1, 2, 3]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([1, 2, 3]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]), array([16, 20, 21, 22, 23, 24, 25]), array([26, 27, 28])]\n","X_test last 100: [array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([29, 30, 31]), array([29, 30, 31]), array([29, 30, 31]), array([29, 30, 31]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([29, 30, 31]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([29, 30, 31]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([32, 33, 34]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([1, 2, 3]), array([32, 33, 34]), array([1, 2, 3]), array([32, 33, 34]), array([32, 33, 34]), array([29, 30, 31]), array([29, 30, 31]), array([29, 30, 31])]\n","Maximum set size: 18\n","Average set size: 2.4210369676974617\n","X_freq [    0 34715 34707 ...     0     1     0]\n","X_dim 5002\n","Maximum feature frequency: 34715\n","Weights: [0.0000000e+00 1.0000000e+00 1.0002305e+00 ... 0.0000000e+00 3.4715000e+04\n"," 0.0000000e+00]\n","The n_folds of non-overlapping random ranges are : [(57017, 57917), (53821, 54721), (32277, 33177)]\n","Number of training/validation folds: 1\n","Number of training instances per fold: 2388\n","Number of validation instances per fold: 588\n","CV_split shape (1, 2, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["k = 5\n","Epoch:  0\n","average precision of subsequent sets: 0.13185999999999998 with std: 0.26213153263199757\n","average recall: 0.18654166666666666 with std: 0.35786032492129916\n","average F score of subsequent sets: 0.15375 with std: 0.30050288997398356\n","average NDCG: 0.17113615565876086\n","average hit rate: 0.1016\n","Epoch:  1\n","average precision of subsequent sets: 0.2067 with std: 0.3008506440079529\n","average recall: 0.3113083333333333 with std: 0.4438988053318008\n","average F score of subsequent sets: 0.247294696969697 with std: 0.35562840751283753\n","average NDCG: 0.29878398792741045\n","average hit rate: 0.248\n","Epoch:  2\n","average precision of subsequent sets: 0.23577999999999996 with std: 0.2932094671050033\n","average recall: 0.34632499999999994 with std: 0.43586436465373024\n","average F score of subsequent sets: 0.2781272727272727 with std: 0.34744003861767214\n","average NDCG: 0.34003783737451704\n","average hit rate: 0.3932\n","Epoch:  3\n","average precision of subsequent sets: 0.25624 with std: 0.2889378175317312\n","average recall: 0.37477499999999997 with std: 0.42219328701108244\n","average F score of subsequent sets: 0.30138441558441553 with std: 0.3387312992524451\n","average NDCG: 0.35996320314958424\n","average hit rate: 0.4518\n","Test recall: [0.18654166666666666, 0.3113083333333333, 0.34632499999999994, 0.37477499999999997]\n","Test ndcg: [0.17113615565876086, 0.29878398792741045, 0.34003783737451704, 0.35996320314958424]\n","Test hit: [0.1016, 0.248, 0.3932, 0.4518]\n","Test precision: [0.13185999999999998, 0.2067, 0.23577999999999996, 0.25624]\n","Test f1: [0.15375, 0.247294696969697, 0.2781272727272727, 0.30138441558441553]\n","Test, k = 5\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-25-5def4c688120>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminMax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'minMax' is not defined"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}